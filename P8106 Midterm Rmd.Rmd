---
title: "P8106 Data Science Homework 2"
author: "Emil Hafeez, eh2928"
geometry: "left=2.57cm,right=2.57cm,top=2.57cm,bottom=2.57cm"
output:
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 3
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lipsum}
- \pagestyle{fancy}
- \fancyhead[R]{\thepage}
- \fancypagestyle{plain}{\pagestyle{fancy}}
--- 

```{r libraries, include = F}
library(caret) 
library(klaR)
library(ggplot2)
library(patchwork)
library(pROC)
library(corrplot)
library(ROSE)
library(tidyverse)
```

```{r opts chunk, include = F}
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
knitr::opts_chunk$set(echo = TRUE)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Parameters for Report
Your report should have the following sections (you can add other sections if you want) and should be no more than 3 pages, excluding figures and tables. The total number of figures and tables should not exceed 6.

# Section 1: Introduction

## Describe your data set. Provide proper motivation for your work.
This dataset contains 5110 observations, with de-identified individual patients as the unit of analysis. Each patient is characterized by their id, and a set of numerical and factor variables detailing basic demographic and biomedical information, like their gender, age, and average glucose level. The outcome of interest is a binary indicator of stroke. There is no information regarding prior stroke history.

While limited information is provided by the data source, this dataset is thought to consider both ischemic and hemorrhagic types of stroke as stroke outcome. These stroke outcomes are both very severe, and very prevalent; stroke is the leading cause of long-term adult disability and the fifth leading cause of death in the United States \(^{1,2}\). Race-ethnicity is also significantly associated with stroke incidence (though not included in this dataset), thereby making investigation a racial justice concern as well. \(^3\). As such a major source of disease, stroke is also quite expensive, estimated at about $34 billion per year due to healthcare services and missed work. As with many illnesses, earlier intervention in potential stroke patients improves outcomes. Were stroke outcomes to be predicted from a small set of predictors set as those available, it may be feasible to provide earlier intervention and preventative care, in order to avert these racial and political economic challenges. 

```{r start clean, include = F, message = F}
stroke_df = read_csv("./data/healthcare-dataset-stroke-data.csv", na = "N/A")

stroke_df = 
  stroke_df %>% 
  mutate(
    id = as.factor(id),
    gender = as.factor(gender),
    hypertension = as.factor(hypertension),
    heart_disease = as.factor(heart_disease),
    ever_married = as.factor(ever_married),
    work_type = as.factor(work_type),
    Residence_type = as.factor(Residence_type),
    smoking_status = as.factor(smoking_status),
    stroke = as.factor(stroke)
  ) %>% 
  rename(residence_type = Residence_type) %>% 
  dplyr::select(id, stroke, gender, age, avg_glucose_level, bmi, everything()) %>% 
    mutate(
    stroke = factor(stroke, labels = make.names(levels(stroke))),
    hypertension = factor(hypertension, labels = make.names(levels(hypertension))),
    heart_disease = factor(heart_disease, labels = make.names(levels(heart_disease)))
  ) %>% 
  dplyr::select(-id) %>% 
  filter(!gender %in% c("Other")) %>% 
  mutate(
    gender = factor(gender)
  )

rnoaa::vis_miss(stroke_df)

stroke_df_no_na = na.omit(stroke_df)

stroke_df_no_na = 
  stroke_df_no_na %>% 
  dplyr::select(stroke, age, avg_glucose_level, bmi, everything())
```

```{r include = F}
summary(stroke_df)
```
## What questions are you trying to answer?

This is a public health example; the current study examines whether a moderately effectively prediction of stroke outcome (as a binary classification) can be made using a relatively low-dimensional dataset with a minimal set of predictors, which are largely demographic and noninvasive. This makes for a classification question. This is in the service of another question: to what extent can such a dataset be thought of as a decision support system for medical practitioners, and/or serve towards an early-screening tool for stroke prevention and resource allocation (focusing on special precautions for those at-risk). Ideally, some insight into which of the factors are most relevant for predicting this outcome could be helpful too. 


## How did you prepare and clean the data?
The data required several preparation and cleaning steps. Essentially, after importing the data, variables were transmuted into more appropriate data types for analysis (for example, character variables into factor variables). Then, the whole dataset was analyzed for missing data, and tidyverse "data tidying" best practices were implemented to rename and reorder variables. All variables were investigated for abnormal values and uncommon responses, as well as missing data. The BMI variable was missing 201 observations, which were assumed to be due to a missing-at-random and thus omitted. Categorical variables were also subject to some technical adjustments in order to allow usage in prediction algorithms. The caret package was used to create testing and training partitions, and some objects (such as a predictor matrix) were created for modeling purposes, as well as any necessary transformations (e.g. centering and scaling).

ADD NEEDEDING TO REBALANCE USING ROSE

# Section 2: Exploratory analysis/visualization

## Is there any interesting structure present in the data?

Data summaries, pair-wise visualizations (boxplots between groups), grouped visualizations (scatter plots with continuous variables and groups), and correlation plots were used. There are many categorical variables, as well as a few nominal and ordinal variables; this presents several challenges for modeling and is a key feature of the data. Other than the missing BMI observations, it is also notable that of the 5110 original observations, only 1 marked "Other" for their gender, which limits the variability modeling can leverage in that regard. 

```{r visualization, include = F}
#histograms
p2 = 
  ggplot(data = stroke_df_no_na) +
  geom_histogram(aes(x = age), fill = "blue", alpha = 0.75) 
p2

p3 = 
  ggplot(data = stroke_df_no_na) +
  geom_histogram(aes(x = avg_glucose_level), fill = "blue", alpha = 0.75) 
p3

p4 = 
  ggplot(data = stroke_df_no_na) +
  geom_histogram(aes(x = bmi), fill = "blue", alpha = 0.75) 
p4

#boxplots
p5 = 
  ggplot(data = stroke_df_no_na) +
  geom_boxplot(aes(x = age, fill = gender), alpha = .75) 
p5

p6 = 
  ggplot(data = stroke_df_no_na) +
  geom_boxplot(aes(x = age, fill = stroke), alpha = .75) +
  scale_fill_discrete(
                      labels=c("No Stroke", "Stroke"))
p6

p7 = 
  ggplot(data = stroke_df_no_na) +
  geom_boxplot(aes(x = avg_glucose_level, fill = gender), alpha = .75) +
  scale_fill_discrete(
                      labels=c("No Stroke", "Stroke"))
p7

#scatters
p1 = 
  ggplot(data = stroke_df_no_na) +
  geom_point(aes(x = avg_glucose_level, y = bmi, color = age), alpha = 0.75)
p1

p8 = 
  ggplot(data = stroke_df_no_na) +
  geom_point(aes(x = avg_glucose_level, y = bmi, color = age, group = stroke), alpha = 0.75) +
  facet_grid(. ~ stroke)
p8

(p2 + p3 + p4) / (p5 + p6 +p7) / (p1 | p8)

stroke_df_no_na$stroke_labs = factor(stroke_df_no_na$stroke)
stroke_df_no_na$stroke_labs = factor(
                                      stroke_df_no_na$stroke, 
                                      levels = c("X0", "X1"), 
                                      labels = c("No Stroke", "Stroke"))

p9 =
  ggplot(data = stroke_df_no_na) +
  geom_point(aes(x = avg_glucose_level, y = bmi, color = age, group = stroke_labs), alpha = 0.75) +
  facet_grid(. ~ stroke_labs) +
  labs(
    title = "Distributions of Average Glucose Level vs BMI, by Stroke Outcome",
    x = "Average Glucose Level",
    y = "BMI",
    caption = "Note the relative absence of younger ages among those with stroke outcomes") +
  theme(plot.title = element_text(hjust = .5))
p9

stroke_df_no_na = 
  stroke_df_no_na %>% 
  select(-stroke_labs)
```

```{r}
corrplot(cor(x), method = "square", type = "upper")
```
## What were your findings?

It is clear from EDA that average glucose level is not normally distributed, exhibiting a bell-like curve near 100 units, but also a heavy right tail with more density around 200 units before reducing again. BMI is bell-shaped though has several high outliers. There is a range of ages in the dataset including high counts from 40 to 60 years old, and a spike near 80 years old. Genders appear approximately equal distributed in age. Interestingly, average glucose level appears approximately the same across the outcome groups (no stroke, and stroke), though the stroke group appears significantly older than the no-stroke group. No correlations between variables are particularly remarkable, other than a moderate positive association between age and having been ever married, and moderate negative association between private employment and self-employment (both of which are transparent, and denote some collinearity).

# Section 3: Models (Biggest section!!)

```{r address imbalance, include=F}
stroke_df_no_na_ROSE = ROSE(
                            stroke ~ . , 
                            data = stroke_df_no_na,
                            p = 0.5, 
                            seed = 1107
                            )$data

```

```{r}
# matrix of predictors
x = model.matrix(stroke ~ ., stroke_df_no_na_ROSE)[,-1]
#vector of response
y = stroke_df_no_na_ROSE$stroke
```

```{r training selection object, include = F}
set.seed(1107)
trRows <- createDataPartition(stroke_df_no_na_ROSE$stroke,
                              p = .75,
                              list = F)
```

```{r modeling 1, include = F}
# Using caret
set.seed(1107)
ctrl <- trainControl(method = "cv",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)
```

```{r modeling approaches and graphs, include = F, cache = T}

#ranger rf
set.seed(1107)
ctrl <- trainControl(method = "cv",
                     classProbs = TRUE, 
                     summaryFunction = twoClassSummary)
#rf
rf.grid <- expand.grid(mtry = 1:11,
                       splitrule = "gini",
                       min.node.size = seq(from = 10, to = 100, by = 10))
set.seed(1107)
rf.fit <- train(stroke ~ . , 
                stroke_df_no_na_ROSE, 
                subset = trRows,
                method = "ranger",
                importance = "permutation",
                tuneGrid = rf.grid,
                metric = "ROC",
                trControl = ctrl)
#coninf tree
set.seed(1107)
ctree.fit <- train(stroke ~ . , 
                   stroke_df_no_na_ROSE, 
                   subset = trRows,
                   method = "ctree",
                   tuneGrid = data.frame(mincriterion = seq(0, 1, length = 10)),
                   metric = "ROC",
                   trControl = ctrl)

## Ridge 
# matrix of predictors (glmnet uses input matrix)
x <- stroke_df_no_na_ROSE[trRows,]
# vector of response
y <- stroke_df_no_na_ROSE$stroke[trRows]
#`alpha` is the elastic net mixing parameter. `alpha=1` is the lasso penalty, and `alpha=0` the ridge penalty. `glmnet()` function standardizes the independent variables by default (The coefficients are always returned on the original scale). 

# fit the ridge regression (alpha = 0) with a sequence of lambdas
ridge.mod <- glmnet(x = x, y = y, 
                    standardize = TRUE,
                    alpha = 0, 
                    lambda = exp(seq(10, -2, length = 100)))

ridge.fit <- train(x, y,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 0, 
                                          lambda = exp(seq(10, -2, length=100))),
                   # preProc = c("center", "scale"),
                   trControl = ctrl1)

plot(ridge.fit, xTrans = log)

ridge.fit$bestTune

# coefficients in the final model
coef(ridge.fit$finalModel, s = ridge.fit$bestTune$lambda)







#gbm ada
gbmA.grid <- expand.grid(n.trees = c(2000,3000,4000),
                         interaction.depth = 1:6,
                         shrinkage = c(0.001,0.003,0.005),
                         n.minobsinnode = c(1,10))
set.seed(1107)
gbmA.fit <- train(stroke ~ . , 
                  stroke_df_no_na_ROSE, 
                  subset = trRows, 
                  tuneGrid = gbmA.grid,
                  trControl = ctrl,
                  method = "gbm",
                  distribution = "adaboost",
                  metric = "ROC",
                  verbose = FALSE)

ggplot(rf.fit, highlight = TRUE)
ggplot(ctree.fit, highlight = TRUE)
ggplot(gbm.fit, highlight = TRUE)
ggplot(gbmA.fit, highlight = TRUE)
```

## What predictor variables did you include?

All variables from the dataset are included in modeling other than the arbitrary numeric identifier. The dataset is not high dimensional, and no variable selection procedures prior to modeling were implemented. Rather than reducing the dimensionality due to a large number of predictor variables, this analysis was primarily affected by the large quantity of categorical variables in the predictor set, since this limited the algorithms which could be applied to the training data.

## What technique did you use? What assumptions, if any, are being made by using this technique?

This application focuses on tree-based methods and ensemble methods, given the predictor space. Specifically, techniques used include random forests, conditional inference trees, and gradient boosting (and adaboost). These methods are utilized because they have few distributional assumptions and are adaptable to our categorical predictors. Random forests makes no formal distributional assumptions, and are non-parametric. Conditional inference trees are closely related to decision trees, but uses a significance test to select inputs rather than maximizing an information measure (like the Gini coefficient used in our RF). Gradient boosting and AdaBoost are used to address the limits of bagging, using weak classifiers and weighting to find best fits and combine classifiers, assuming that observations are independent, and sometimes assumptions about the interaction depth (though this is tuned here).

## If there were tuning parameters, how did you pick their values?

Tuning parameters include the minimum node size in the random forest algorithm and the minimum criterion in the conditional inference trees; the gradient boosting algorithm and the Adaptive Boosting version tunes the number of trees, interaction dept, shrinkage, and the minimum number of observations in each node. These were tuned using cross-validation, using a wider range and coarser search pattern; after locating approximate ranges for the selected parameters, I then iterated the search pattern within a narrower ranger and with more granular steps.

## Discuss the training/test performance if you have a test data set.
Comment on the below.
Regarding the training data performance,
```{r modeling 3 comparison, include = F}
res <- resamples(list(
                      rf = rf.fit,
                      ctree = ctree.fit,
                      gbm = gbm.fit,
                      gbma = gbmA.fit
                      )
                 )
summary(res)

bwplot(res, metric = "ROC")
```
Regarding the testing data performance,
```{r modeling 4 test performance, include = F}
rf.pred <- predict(rf.fit, newdata = stroke_df_no_na_ROSE[-trRows,], type = "prob")[,1]
ctree.pred <- predict(ctree.fit, newdata = stroke_df_no_na_ROSE[-trRows,], type = "prob")[,1]
gbm.pred <- predict(gbm.fit, newdata = stroke_df_no_na_ROSE[-trRows,], type = "prob")[,1]
gbmA.pred <- predict(gbmA.fit, newdata = stroke_df_no_na_ROSE[-trRows,], type = "prob")[,1]

roc.rf <- roc(stroke_df_no_na_ROSE$stroke[-trRows], rf.pred)
roc.ctree <- roc(stroke_df_no_na_ROSE$stroke[-trRows], ctree.pred)
roc.gbm <- roc(stroke_df_no_na_ROSE$stroke[-trRows], gbm.pred)
roc.gbmA <- roc(stroke_df_no_na_ROSE$stroke[-trRows], gbmA.pred)

auc <- c(roc.rf$auc[1], roc.ctree$auc[1], roc.gbm$auc[1],
         roc.gbmA$auc[1])

#plot
plot(roc.rf, legacy.axes = TRUE)
plot(roc.ctree, col = 2, add = TRUE)
plot(roc.gbm, col = 3, add = TRUE)
plot(roc.gbmA, col = 4, add = TRUE)
modelNames <- c("rf","ctree","gbm","gbmA")
legend("bottomright", legend = paste0(modelNames, ": ", round(auc,3)),
       col = 1:4, lwd = 2)
```

## Which variables play important roles in predicting the response?

Variable importance is computed by permutations, implemented during model training. Having extracted these results from each model, one can see there is relative consistency between approaches as to which variables are most important: age, average glucose level, hypertension, currently smokes, and BMI.

```{r}
## add variable importance 
varImp(rf.fit)
varImp(ctree.fit)

#For importance scores generated from varImp.train, a plot method can be used to visualize the results. In the plot below, the top option is used to make the image more readable.
plot(gbmImp, top = 20)

#Variable importance from boosting can be obtained using the `summary()` function.
summary(gbm.fit$finalModel, las = 2, cBars = 19, cex.names = 0.6)
summary(gbmA.fit$finalModel, las = 2, cBars = 19, cex.names = 0.6)
```

## What are the limitations of the models you used (if there are any)? Are the models flexible enough to capture the underlying truth?

All of these methods can be limited in their interpretability; while their flexibility is particularly useful for underlying complex truths, they are black-box methods where we have limited control over the models' findings and interpretation. Since, generally speaking, bagging methods reduce variance by applying the same algorithm to a bootstrapped sample (sampling with replacement), and boosting can help to reduce bias by weighting weak learners, it is wise to apply both. We know due to the bias-variance tradeoff that these characteristics are in tension, and seek to capture the underlying truth by examining both options separately.

"An advantage of using this method is that it leads to no information loss. The disadvantage of using this method is that, since oversampling simply adds replicated observations in original data set, it ends up adding multiple observations of several types, thus leading to overfitting. Although, the training accuracy of such data set will be high, but the accuracy on unseen data will be worse."

# Section 4: Conclusions

## What were your findings? Are they what you expect? What insights into the data can you make?


#Section 5: Bibliography
1. Boehme, AK, Esenwa, C, & Elkind, MSV. Stroke risk factors, genetics, and prevention. Circulation Research. 2017; Retrieved 3/24/2021, from https://www.ahajournals.org/doi/full/10.1161/CIRCRESAHA.116.308398

2. Roger VL, Go AS, Lloyd-Jones DM, et al.; American Heart Association Statistics Committee and Stroke Statistics Subcommittee. Heart disease and stroke statistics–2011 update: a report from the American Heart Association. Circulation. 2011; 123:e18–e209. doi: 10.1161/CIR.0b013e3182009701.

3. Howard VJ, Kleindorfer DO, Judd SE, McClure LA, Safford MM, Rhodes JD, Cushman M, Moy CS, Soliman EZ, Kissela BM, Howard G. Disparities in stroke incidence contributing to disparities in stroke mortality. Annals of Neurol. 2011; 69:619–627. doi: 10.1002/ana.22385

4. Giles, MF. Rothwell, PM. 2007. Risk of stroke early after transient ischaemic attack: a systematic review and meta-analysis. Neurology. 6:12, 1063-1072, doi: 10.1016/S1474-4422(07)70274-0. 

#Section 666: OPEN QUESTIONS
# Questions for office hours


WHICH OF THE EDA PLOTS TO KEEP IN THE REPORT?

-wait for finish model fitting. check resample and auc.
-implement ROSE, plot the changes, change the model fitting using new dataset
-rerun model fitting


NOW:


--take out gbm
--add ridge
--compare ROSE training and regular training
--
-check variable importances are the same from the extraction method and the permutation setting are the same.

